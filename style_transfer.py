import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
import torchvision.transforms as transforms
from torchvision.models import vgg19, VGG19_Weights
from PIL import Image
import sys
import os

device = 'cuda' if torch.cuda.is_available() else 'cpu'

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def load_image(path):
    transform = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor()
    ])
    image = Image.open(path).convert("RGB")
    image = transform(image).unsqueeze(0)
    return image.to(device)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def save_output(tensor, path):
    image = tensor.clone().detach().cpu().squeeze(0)
    image = transforms.ToPILImage()(image)
    image.save(path)

# –ú–æ–¥–µ–ª—å VGG –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
class VGG(nn.Module):
    def __init__(self):
        super(VGG, self).__init__()
        self.req_features = ['0', '5', '10', '19', '28']
        self.model = vgg19(weights=VGG19_Weights.DEFAULT).features[:29]


    def forward(self, x):
        features = []
        for layer_num, layer in enumerate(self.model):
            x = layer(x)
            if str(layer_num) in self.req_features:
                features.append(x)
        return features

# –ü–æ—Ç–µ—Ä–∏
def content_loss(g, o):
    return torch.mean((g - o) ** 2)

def style_loss(g, s):
    b, c, h, w = g.shape
    G = torch.mm(g.view(c, h * w), g.view(c, h * w).t())
    A = torch.mm(s.view(c, h * w), s.view(c, h * w).t())
    return torch.mean((G - A) ** 2)

def calculate_total_loss(gf, cf, sf, alpha=8, beta=70):
    c_loss = 0
    s_loss = 0
    for g, c, s in zip(gf, cf, sf):
        c_loss += content_loss(g, c)
        s_loss += style_loss(g, s)
    return alpha * c_loss + beta * s_loss

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å—Ç–∏–ª—è
def extract_style(style_image_path, out_tensor_path):
    try:
        model = VGG().to(device).eval()
        image = load_image(style_image_path)
        features = model(image)
        torch.save(features, out_tensor_path)
        print(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ç–∏–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {out_tensor_path}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç–∏–ª—è: {e}", file=sys.stderr)
        if os.path.exists(out_tensor_path):
            try:
                os.remove(out_tensor_path)
                print(f"üóë –£–¥–∞–ª—ë–Ω —á–∞—Å—Ç–∏—á–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª: {out_tensor_path}")
            except Exception as rmErr:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {out_tensor_path}: {rmErr}", file=sys.stderr)
        sys.exit(1)


# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∏–ª—è –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
def apply_style(content_path, style_tensor_path, output_path):
    model = VGG().to(device).eval()
    content = load_image(content_path)
    style_feat = torch.load(style_tensor_path, weights_only=False)
    generated = content.clone().requires_grad_(True)

    optimizer = optim.Adam([generated], lr=0.004)
    epochs = 1

    try:
        for i in range(epochs):
            gen_feat = model(generated)
            cont_feat = model(content)

            loss = calculate_total_loss(gen_feat, cont_feat, style_feat)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if i % 100 == 0:
                print(f"[{i}/{epochs}] Loss: {loss.item():.4f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤—Å—ë –ø—Ä–æ—à–ª–æ –±–µ–∑ exception
        save_output(generated, output_path)
        print(f"‚úÖ –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_path}")

    except Exception as e:
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏: {e}", file=sys.stderr)
        # –£–¥–∞–ª—è–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —á–∞—Å—Ç–∏—á–Ω–æ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists(output_path):
            try:
                os.remove(output_path)
                print(f"üóë –£–¥–∞–ª—ë–Ω –Ω–µ–ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª: {output_path}")
            except OSError as rmErr:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {output_path}: {rmErr}", file=sys.stderr)
        # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å –æ—à–∏–±–∫–æ–π
        sys.exit(1)
# CLI
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
              "  extract-style <style.jpg> <style.pt>\n"
              "  stylize <content.jpg> <style.pt> <output.jpg>")
        sys.exit(1)

    command = sys.argv[1]

    if command == "extract-style" and len(sys.argv) == 4:
        extract_style(sys.argv[2], sys.argv[3])

    elif command == "stylize" and len(sys.argv) == 5:
        apply_style(sys.argv[2], sys.argv[3], sys.argv[4])

    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.")
        sys.exit(1)
